{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data, Dataset\n",
    "import networkx as nx\n",
    "from networkx.algorithms.centrality import betweenness_centrality\n",
    "\n",
    "from Datasets.synthetics import BA_2grid, BA_2grid_house, ProbingDataset, BA_2grid_to_test\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "import torch_geometric.utils as pyg_utils\n",
    "import networkx as nx\n",
    "from networkx.algorithms.centrality import betweenness_centrality\n",
    "\n",
    "import pickle as pkl\n",
    "from torch_geometric.utils import from_networkx\n",
    "import random\n",
    "\n",
    "from models.models_BA_2grid import GCN_framework as framework\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    if seed == -1:\n",
    "        seed = random.randint(0, 1000)\n",
    "    # Pandas also uses np random state by default\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    # if you are using GPU\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.enabled = False\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(43)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Graph-Features Dataset\n",
    "\n",
    "The features for BA-2grid-house and ER-nb_stars2 datasets:\n",
    "- num_nodes\n",
    "- num_edges\n",
    "- density\n",
    "- average_shortest_path_length\n",
    "- transitivity\n",
    "- average_clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "probing_dataset = ProbingDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ProbingDataset(2000)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probing_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnn_dataset_to_test = BA_2grid_to_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = torch.arange(len(gnn_dataset_to_test))\n",
    "train_idx, test_idx = train_test_split(idx, train_size=0.8,random_state=10)\n",
    "\n",
    "train_loader = DataLoader(gnn_dataset_to_test[train_idx],batch_size=256)\n",
    "test_loader = DataLoader(gnn_dataset_to_test[test_idx],batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have a list of graphs in your dataset\n",
    "idx = torch.arange(len(probing_dataset))\n",
    "train_idx, test_idx = train_test_split(idx, train_size=0.8,random_state=10)\n",
    "\n",
    "probe_train_loader = DataLoader(probing_dataset[train_idx],batch_size=256)\n",
    "probe_test_loader = DataLoader(probing_dataset[test_idx],batch_size=256)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model to Probe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mara/anaconda3/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:157: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "MODEL = \"GCN\"\n",
    "DATASET = \"BA_2grid\"\n",
    "dataset = BA_2grid()\n",
    "gnn = framework(dataset,device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6991686612894952"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model\n",
    "gnn.train()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train probe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Probe(torch.nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(Probe, self).__init__()\n",
    "        self.fc = torch.nn.Linear(input_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc(x.float())\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_probe(probe, gnn, layer_idx):\n",
    "    gnn.model.eval()\n",
    "    probe.train()\n",
    "    \n",
    "    total_loss = 0\n",
    "    loss_fn = torch.nn.MSELoss()\n",
    "    optimizer = optim.Adam(probe.parameters(), lr=0.001)\n",
    "\n",
    "    for graph in probe_train_loader:\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = gnn.model(graph.x, graph.edge_index, graph.batch)\n",
    "        output = torch.sum(output, dim=1)\n",
    "        labels = graph.y.reshape(int(len(graph.y)/6), 6)\n",
    "        padded_output = torch.nn.functional.pad(output, (0, 256 - int(len(graph.y)/6)))\n",
    "        output = probe(padded_output)\n",
    "        \n",
    "        \n",
    "        loss = loss_fn(output, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += float(loss) * graph.num_graphs\n",
    "    return total_loss / len(probe_train_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "def evaluate_probe(probe, test_loader):\n",
    "    probe.eval()\n",
    "\n",
    "    mse = 0\n",
    "    r2 = 0\n",
    "    total = 0\n",
    "    loss_fn = torch.nn.MSELoss()\n",
    "    \n",
    "    for graph in test_loader:\n",
    "\n",
    "        output = gnn.model(graph.x, graph.edge_index, graph.batch)\n",
    "        output = torch.sum(output, dim=1)\n",
    "        y_true = graph.y.reshape(int(len(graph.y)/6), 6)\n",
    "        padded_output = torch.nn.functional.pad(output, (0, 256 - int(len(graph.y)/6)))\n",
    "        y_pred = probe(padded_output)\n",
    "\n",
    "        mse += loss_fn(y_pred, y_true)\n",
    "        # r2 += r2_score(y_true, y_pred)\n",
    "        total += 1\n",
    "    \n",
    "    return {\n",
    "        \"MSE\": mse/total\n",
    "        # \"R2 Score\": r2/total\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_to_train(gnn, layer_idx, num_epochs=10):\n",
    "    probe = Probe(256, 6)\n",
    "    losses = []\n",
    "    test_losses = []\n",
    "    for epoch in range(num_epochs):\n",
    "        loss = train_probe(probe, gnn, layer_idx)\n",
    "        losses.append(loss)\n",
    "        result = evaluate_probe(probe, probe_test_loader)\n",
    "        test_acc = result['MSE']\n",
    "        test_losses.append(test_acc)\n",
    "        print(f'Epoch: {epoch:03d}, '\n",
    "              f'Test MSE: {test_acc:.3f}',\n",
    "              f'Train MSE: {loss:.3f}')\n",
    "        # print(f'Epoch: {epoch:03d}, '\n",
    "        #       f'Loss: {loss:.3f}, ')\n",
    "    return probe, losses, test_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mara/anaconda3/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([256, 6])) that is different to the input size (torch.Size([6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/mara/anaconda3/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64, 6])) that is different to the input size (torch.Size([6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/mara/anaconda3/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([144, 6])) that is different to the input size (torch.Size([6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Test MSE: 227.346 Train MSE: 233.254\n",
      "Epoch: 001, Test MSE: 212.227 Train MSE: 214.217\n",
      "Epoch: 002, Test MSE: 197.887 Train MSE: 196.312\n",
      "Epoch: 003, Test MSE: 184.328 Train MSE: 179.532\n",
      "Epoch: 004, Test MSE: 171.595 Train MSE: 163.826\n",
      "Epoch: 005, Test MSE: 159.317 Train MSE: 148.936\n",
      "Epoch: 006, Test MSE: 147.609 Train MSE: 134.801\n",
      "Epoch: 007, Test MSE: 136.375 Train MSE: 121.423\n",
      "Epoch: 008, Test MSE: 125.705 Train MSE: 108.800\n",
      "Epoch: 009, Test MSE: 115.513 Train MSE: 96.934\n",
      "Epoch: 010, Test MSE: 105.884 Train MSE: 85.824\n",
      "Epoch: 011, Test MSE: 96.735 Train MSE: 75.472\n",
      "Epoch: 012, Test MSE: 88.147 Train MSE: 65.875\n",
      "Epoch: 013, Test MSE: 80.042 Train MSE: 57.036\n",
      "Epoch: 014, Test MSE: 72.498 Train MSE: 48.952\n",
      "Epoch: 015, Test MSE: 65.439 Train MSE: 41.626\n",
      "Epoch: 016, Test MSE: 58.941 Train MSE: 35.056\n",
      "Epoch: 017, Test MSE: 52.931 Train MSE: 29.243\n",
      "Epoch: 018, Test MSE: 47.483 Train MSE: 24.184\n",
      "Epoch: 019, Test MSE: 42.526 Train MSE: 19.881\n",
      "Epoch: 020, Test MSE: 38.134 Train MSE: 16.328\n",
      "Epoch: 021, Test MSE: 34.243 Train MSE: 13.524\n",
      "Epoch: 022, Test MSE: 30.985 Train MSE: 11.462\n",
      "Epoch: 023, Test MSE: 29.110 Train MSE: 10.130\n",
      "Epoch: 024, Test MSE: 27.449 Train MSE: 9.235\n",
      "Epoch: 025, Test MSE: 26.160 Train MSE: 8.710\n",
      "Epoch: 026, Test MSE: 25.640 Train MSE: 8.538\n",
      "Epoch: 027, Test MSE: 25.768 Train MSE: 8.534\n",
      "Epoch: 028, Test MSE: 25.626 Train MSE: 8.512\n",
      "Epoch: 029, Test MSE: 25.597 Train MSE: 8.501\n",
      "Epoch: 030, Test MSE: 25.523 Train MSE: 8.483\n",
      "Epoch: 031, Test MSE: 25.462 Train MSE: 8.470\n",
      "Epoch: 032, Test MSE: 25.403 Train MSE: 8.454\n",
      "Epoch: 033, Test MSE: 25.335 Train MSE: 8.441\n",
      "Epoch: 034, Test MSE: 25.281 Train MSE: 8.424\n",
      "Epoch: 035, Test MSE: 25.210 Train MSE: 8.411\n",
      "Epoch: 036, Test MSE: 25.158 Train MSE: 8.396\n",
      "Epoch: 037, Test MSE: 25.086 Train MSE: 8.382\n",
      "Epoch: 038, Test MSE: 25.035 Train MSE: 8.367\n",
      "Epoch: 039, Test MSE: 24.962 Train MSE: 8.353\n",
      "Epoch: 040, Test MSE: 24.913 Train MSE: 8.337\n",
      "Epoch: 041, Test MSE: 24.840 Train MSE: 8.324\n",
      "Epoch: 042, Test MSE: 24.791 Train MSE: 8.308\n",
      "Epoch: 043, Test MSE: 24.718 Train MSE: 8.294\n",
      "Epoch: 044, Test MSE: 24.670 Train MSE: 8.280\n",
      "Epoch: 045, Test MSE: 24.596 Train MSE: 8.266\n",
      "Epoch: 046, Test MSE: 24.548 Train MSE: 8.250\n",
      "Epoch: 047, Test MSE: 24.475 Train MSE: 8.237\n",
      "Epoch: 048, Test MSE: 24.427 Train MSE: 8.222\n",
      "Epoch: 049, Test MSE: 24.354 Train MSE: 8.209\n",
      "Epoch: 050, Test MSE: 24.307 Train MSE: 8.194\n",
      "Epoch: 051, Test MSE: 24.234 Train MSE: 8.180\n",
      "Epoch: 052, Test MSE: 24.187 Train MSE: 8.165\n",
      "Epoch: 053, Test MSE: 24.115 Train MSE: 8.151\n",
      "Epoch: 054, Test MSE: 24.067 Train MSE: 8.137\n",
      "Epoch: 055, Test MSE: 23.995 Train MSE: 8.124\n",
      "Epoch: 056, Test MSE: 23.948 Train MSE: 8.108\n",
      "Epoch: 057, Test MSE: 23.876 Train MSE: 8.096\n",
      "Epoch: 058, Test MSE: 23.829 Train MSE: 8.080\n",
      "Epoch: 059, Test MSE: 23.758 Train MSE: 8.067\n",
      "Epoch: 060, Test MSE: 23.711 Train MSE: 8.053\n",
      "Epoch: 061, Test MSE: 23.640 Train MSE: 8.040\n",
      "Epoch: 062, Test MSE: 23.593 Train MSE: 8.024\n",
      "Epoch: 063, Test MSE: 23.523 Train MSE: 8.012\n",
      "Epoch: 064, Test MSE: 23.476 Train MSE: 7.997\n",
      "Epoch: 065, Test MSE: 23.406 Train MSE: 7.983\n",
      "Epoch: 066, Test MSE: 23.359 Train MSE: 7.969\n",
      "Epoch: 067, Test MSE: 23.290 Train MSE: 7.956\n",
      "Epoch: 068, Test MSE: 23.242 Train MSE: 7.941\n",
      "Epoch: 069, Test MSE: 23.174 Train MSE: 7.929\n",
      "Epoch: 070, Test MSE: 23.126 Train MSE: 7.914\n",
      "Epoch: 071, Test MSE: 23.058 Train MSE: 7.901\n",
      "Epoch: 072, Test MSE: 23.011 Train MSE: 7.887\n",
      "Epoch: 073, Test MSE: 22.943 Train MSE: 7.874\n",
      "Epoch: 074, Test MSE: 22.895 Train MSE: 7.859\n",
      "Epoch: 075, Test MSE: 22.828 Train MSE: 7.847\n",
      "Epoch: 076, Test MSE: 22.781 Train MSE: 7.832\n",
      "Epoch: 077, Test MSE: 22.714 Train MSE: 7.820\n",
      "Epoch: 078, Test MSE: 22.666 Train MSE: 7.805\n",
      "Epoch: 079, Test MSE: 22.601 Train MSE: 7.792\n",
      "Epoch: 080, Test MSE: 22.553 Train MSE: 7.778\n",
      "Epoch: 081, Test MSE: 22.487 Train MSE: 7.766\n",
      "Epoch: 082, Test MSE: 22.439 Train MSE: 7.752\n",
      "Epoch: 083, Test MSE: 22.374 Train MSE: 7.739\n",
      "Epoch: 084, Test MSE: 22.326 Train MSE: 7.725\n",
      "Epoch: 085, Test MSE: 22.262 Train MSE: 7.713\n",
      "Epoch: 086, Test MSE: 22.214 Train MSE: 7.698\n",
      "Epoch: 087, Test MSE: 22.150 Train MSE: 7.686\n",
      "Epoch: 088, Test MSE: 22.102 Train MSE: 7.672\n",
      "Epoch: 089, Test MSE: 22.038 Train MSE: 7.660\n",
      "Epoch: 090, Test MSE: 21.991 Train MSE: 7.645\n",
      "Epoch: 091, Test MSE: 21.928 Train MSE: 7.633\n",
      "Epoch: 092, Test MSE: 21.880 Train MSE: 7.619\n",
      "Epoch: 093, Test MSE: 21.817 Train MSE: 7.607\n",
      "Epoch: 094, Test MSE: 21.769 Train MSE: 7.593\n",
      "Epoch: 095, Test MSE: 21.707 Train MSE: 7.581\n",
      "Epoch: 096, Test MSE: 21.659 Train MSE: 7.567\n",
      "Epoch: 097, Test MSE: 21.597 Train MSE: 7.555\n",
      "Epoch: 098, Test MSE: 21.549 Train MSE: 7.541\n",
      "Epoch: 099, Test MSE: 21.488 Train MSE: 7.529\n"
     ]
    }
   ],
   "source": [
    "probe, losses, test_acc = iterate_to_train(gnn, 0, num_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f0cd0bbe640>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAigAAAGdCAYAAAA44ojeAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAv2klEQVR4nO3de3xU5b3v8e+aSTK5kAwkgUxCAgYFQYIIQVGKAopYirqt7nqrFk893bUq2xStltpzyulpwXrOVk9ftnbrtuK1uN2KtZVWY8UIpQpyUS4KKAESyBAIIZOQe2adP5IZMiGBXGay5vJ5v17zwsx61sxvnqTNN896nmcZpmmaAgAACCM2qwsAAADoioACAADCDgEFAACEHQIKAAAIOwQUAAAQdggoAAAg7BBQAABA2CGgAACAsBNndQH94fV6dejQIaWmpsowDKvLAQAAvWCapmpra5WTkyOb7fRjJBEZUA4dOqS8vDyrywAAAP1QVlam3Nzc07aJyICSmpoqqf0DpqWlWVwNAADoDY/Ho7y8PP/v8dOJyIDiu6yTlpZGQAEAIML0ZnoGk2QBAEDYIaAAAICwQ0ABAABhh4ACAADCDgEFAACEHQIKAAAIOwQUAAAQdggoAAAg7BBQAABA2CGgAACAsENAAQAAYYeAAgAAwk5E3iwwVA4db9DLH+9Xa5upJd+YYHU5AADELEZQOqlvbtVv1nyllz8+INM0rS4HAICYRUDpZHRGiuJshuqaWuX2NFpdDgAAMYuA0km83abRGcmSpC8r6yyuBgCA2EVA6eKcEUMkEVAAALASAaULX0DZQ0ABAMAyBJQuGEEBAMB6BJQuzhmeKkn6ioACAIBlCChdnD0iRZJUdaJZ1SeaLa4GAIDYREDpIjkhTiOHJkmSvjzCKAoAAFYgoHTDP1H2MAEFAAArEFC6wURZAACsRUDphj+gcIkHAABLEFC64QsorOQBAMAaBJRunDO8PaAcPN6gE02tFlcDAEDsIaB0Y1hKgjJSEiRJe4+csLgaAABiDwGlB2f7t7yvtbgSAABiDwGlB2NZyQMAgGUIKD1gqTEAANYhoPSApcYAAFiHgNIDX0DZX1Wv5lavxdUAABBbCCg9cKUlaogjTm1eU/uqWMkDAMBgIqD0wDAMnT28/c7GzEMBAGBwEVBO42wmygIAYAkCymmwkgcAAGsQUE5j7IhUSQQUAAAGGwHlNPw3DTxSpzavaXE1AADEDgLKaeQNS1KC3aamVq8OVjdYXQ4AADGDgHIacXab8jM7VvIc4Z48AAAMFgLKGTBRFgCAwUdAOYOxWe0BZfdhAgoAAIOFgHIG52a1r+TZfZhLPAAADBYCyhmM7Qgoew7XyctKHgAABgUB5QzOykhWgt2mhpY2lbOSBwCAQUFAOYM4u82/5f0uLvMAADAoCCi9cK5/oiwBBQCAwUBA6YVxLibKAgAwmAgovTCu4548u9wEFAAABgMBpRfO7RhB2XvkhFravBZXAwBA9COg9MLIoUlKTrCruc2r/VUnrC4HAICoR0DpBZvN8O+Hwo6yAACEHgGll8b5lhozDwUAgJAjoPTSuazkAQBg0BBQemlcxyUeNmsDACD0CCi95BtB2V9Vr8aWNourAQAguhFQemlEqkNpiXFq85rae4SVPAAAhBIBpZcMw2AeCgAAg6RPAWX58uW68MILlZqaqhEjRui6667Trl27AtqYpqmlS5cqJydHSUlJmj17tnbs2BHQpqmpSYsWLVJmZqZSUlJ07bXXqry8fOCfJsTGZRFQAAAYDH0KKCUlJbrnnnv00Ucfqbi4WK2trZo3b55OnDh5yePRRx/VY489pieffFIbN26Uy+XSlVdeqdrak7/Ui4qKtGrVKq1cuVLr1q1TXV2drr76arW1hffcDkZQAAAYHIZpmmZ/Tz5y5IhGjBihkpISXXbZZTJNUzk5OSoqKtJDDz0kqX20JCsrS7/61a/0/e9/XzU1NRo+fLhefPFF3XTTTZKkQ4cOKS8vT6tXr9ZVV111xvf1eDxyOp2qqalRWlpaf8vvs4/2Vunmpz9SXnqS1j54+aC9LwAA0aAvv78HNAelpqZGkpSeni5JKi0tldvt1rx58/xtHA6HZs2apfXr10uSNm3apJaWloA2OTk5Kigo8LfpqqmpSR6PJ+BhBd8lnrJjDTrR1GpJDQAAxIJ+BxTTNLV48WLNnDlTBQUFkiS32y1JysrKCmiblZXlP+Z2u5WQkKBhw4b12Kar5cuXy+l0+h95eXn9LXtA0lMSlDnEIUn6spIt7wEACJV+B5R7771Xn332mf7whz+ccswwjICvTdM85bmuTtdmyZIlqqmp8T/Kysr6W/aAnevq2PKeeSgAAIRMvwLKokWL9NZbb2nNmjXKzc31P+9yuSTplJGQyspK/6iKy+VSc3Ozqqure2zTlcPhUFpaWsDDKv6VPNyTBwCAkOlTQDFNU/fee6/eeOMNvf/++8rPzw84np+fL5fLpeLiYv9zzc3NKikp0YwZMyRJhYWFio+PD2hTUVGh7du3+9uEM7a8BwAg9OL60viee+7RK6+8oj/+8Y9KTU31j5Q4nU4lJSXJMAwVFRVp2bJlGjt2rMaOHatly5YpOTlZt956q7/tnXfeqfvvv18ZGRlKT0/XAw88oEmTJmnu3LnB/4RB5gsoew4zBwUAgFDpU0B56qmnJEmzZ88OeP65557THXfcIUl68MEH1dDQoLvvvlvV1dWaPn263n33XaWmpvrbP/7444qLi9ONN96ohoYGXXHFFVqxYoXsdvvAPs0gGJfVPgfF7WnU8fpmDU1OsLgiAACiz4D2QbGKVfug+Mz81fsqr27QH753sS45O2PQ3x8AgEg0aPugxKoJ2e2d+oXbmv1YAACIdgSUfpjQseX95xUEFAAAQoGA0g++EZTPK1jJAwBAKBBQ+sEXUHYfrlVrm9fiagAAiD4ElH4YlZ6s5AS7mlq92ld14swnAACAPiGg9IPNZujcjnkoO7nMAwBA0BFQ+unkPBQmygIAEGwElH7yreT5goACAEDQEVD6iZU8AACEDgGln3xzUNyeRlWfaLa4GgAAogsBpZ9SE+OVl54kSfqcHWUBAAgqAsoATHBxmQcAgFAgoAwAK3kAAAgNAsoATMjuWMnDJR4AAIKKgDIAJ7e8r2PLewAAgoiAMgB5w5KVkmBXc6tXe4+y5T0AAMFCQBmAzlveMw8FAIDgIaAMEBu2AQAQfASUARrPSh4AAIKOgDJA52VziQcAgGAjoAzQuR2btVXWNqmqrsniagAAiA4ElAEa4ojTqPRkSdIXbuahAAAQDASUIJjAZR4AAIKKgBIEvpU8Ow8RUAAACAYCShAU5DglSTsIKAAABAUBJQgmjmwfQdlTWauG5jaLqwEAIPIRUILAlZaojJQEeU1uHAgAQDAQUILAMAxNHMllHgAAgoWAEiQFOe2XeXYcqrG4EgAAIh8BJUgKOkZQth9kBAUAgIEioASJbyXPLnetmlu9FlcDAEBkI6AESV56klIT49Tc5tWeSnaUBQBgIAgoQWIYxsn9ULjMAwDAgBBQgqigYz+U7UyUBQBgQAgoQTSRHWUBAAgKAkoQ+UZQdh7yqM1rWlwNAACRi4ASRPmZQ5QUb1dDS5tKj9ZZXQ4AABGLgBJEdpuh8zo2bGM/FAAA+o+AEmQF/oDCRFkAAPqLgBJkvnvysJIHAID+I6AEWUGnlTymyURZAAD6g4ASZGOzhijBblNtY6vKjjVYXQ4AABGJgBJk8XabxmenSuIyDwAA/UVACYGJTJQFAGBACCgh4NtRdjs7ygIA0C8ElBAoGOm7aWANE2UBAOgHAkoIjHelym4zVHWiWW5Po9XlAAAQcQgoIZAYb9fYEUMkSZ+VMw8FAIC+IqCEyOTcoZKkz8qPW1oHAACRiIASIpNy2+ehMIICAEDfEVBCxDeCso2JsgAA9BkBJUTOdaUqwW7T8foWdpQFAKCPCCghkhBn04SOHWU/ZR4KAAB9QkAJofOZKAsAQL8QUEKIibIAAPQPASWEfBNltx+sUZuXibIAAPQWASWEzhkxREnxdp1oblPp0TqrywEAIGIQUELIbjNUMLL9zsaflnGZBwCA3iKghBgTZQEA6DsCSoid75soe5ARFAAAeouAEmK+EZSdhzxqafNaWwwAABGCgBJiZ2UkKzUxTk2tXu0+XGt1OQAARAQCSogZhnHyMg/7oQAA0Ct9DigffvihrrnmGuXk5MgwDL355psBx++44w4ZhhHwuPjiiwPaNDU1adGiRcrMzFRKSoquvfZalZeXD+iDhLOTE2UJKAAA9EafA8qJEyc0efJkPfnkkz22+frXv66Kigr/Y/Xq1QHHi4qKtGrVKq1cuVLr1q1TXV2drr76arW1tfX9E0SAyf4RlOPWFgIAQISI6+sJ8+fP1/z580/bxuFwyOVydXuspqZGzz77rF588UXNnTtXkvTSSy8pLy9P7733nq666qq+lhT2JnWMoOxy16qxpU2J8XZrCwIAIMyFZA7KBx98oBEjRmjcuHH63ve+p8rKSv+xTZs2qaWlRfPmzfM/l5OTo4KCAq1fv77b12tqapLH4wl4RJIcZ6IyhySo1Wvq84rIqh0AACsEPaDMnz9fL7/8st5//33927/9mzZu3KjLL79cTU1NkiS3262EhAQNGzYs4LysrCy53e5uX3P58uVyOp3+R15eXrDLDqn2ibJDJTEPBQCA3gh6QLnpppu0YMECFRQU6JprrtFf/vIX7d69W2+//fZpzzNNU4ZhdHtsyZIlqqmp8T/KysqCXXbITRrZPg/lU+ahAABwRiFfZpydna3Ro0drz549kiSXy6Xm5mZVV1cHtKusrFRWVla3r+FwOJSWlhbwiDQX5A2VJH1adtzSOgAAiAQhDyhVVVUqKytTdna2JKmwsFDx8fEqLi72t6moqND27ds1Y8aMUJdjmckdAeWrIydUU99ibTEAAIS5Pq/iqaur05dffun/urS0VFu3blV6errS09O1dOlS3XDDDcrOzta+ffv0k5/8RJmZmfrmN78pSXI6nbrzzjt1//33KyMjQ+np6XrggQc0adIk/6qeaJSekqDRGcnaX1WvT8uP67Jxw60uCQCAsNXngPLJJ59ozpw5/q8XL14sSVq4cKGeeuopbdu2TS+88IKOHz+u7OxszZkzR6+++qpSU1P95zz++OOKi4vTjTfeqIaGBl1xxRVasWKF7PboXn47JW+o9lfVa2sZAQUAgNMxTNM0rS6irzwej5xOp2pqaiJqPsqKv5dq6Z92as65w/Xcf7vI6nIAABhUffn9zb14BtGUUe1Lq7eWHVcE5kIAAAYNAWUQTchOU0KcTdX1LdpfVW91OQAAhC0CyiBKiLNpYk77kNZWlhsDANAjAsogm5LXfplny4HqM7QEACB2EVAG2QWjhkpiBAUAgNMhoAyyKR0btu2s8Kixpc3aYgAACFMElEGWOyxJmUMS1NJmasch7mwMAEB3CCiDzDAM/315uMwDAED3CCgW8O2HwkRZAAC6R0CxACMoAACcHgHFAufnOmUYUnl1g47UNlldDgAAYYeAYoHUxHiNHTFEEqMoAAB0h4BiEd9lHuahAABwKgKKRTrfOBAAAAQioFjEN4LyWXmN2rzc2RgAgM4IKBYZl5Wq5AS76ppa9WVlndXlAAAQVggoFrHbDE3OHSpJ2sw8FAAAAhBQLFQ4un0eyif7CCgAAHRGQLFQ4VntAWXT/mMWVwIAQHghoFhoal57QNlXVa+jdWzYBgCADwHFQs7keI3Lat+wbdN+LvMAAOBDQLGYbx7KZgIKAAB+BBSLFY5OlyR9QkABAMCPgGKxaR0jKNvKa9TU2mZxNQAAhAcCisVGZyQrIyVBzW1ebT9YY3U5AACEBQKKxQzD8M9DYaIsAADtCChhgA3bAAAIREAJA9POOjmCYprcOBAAAAJKGJiY41SC3aaqE83aX1VvdTkAAFiOgBIGEuPtmpTrlMRyYwAAJAJK2GCiLAAAJxFQwsTJgMKNAwEAIKCECV9A2X24TjUNLRZXAwCAtQgoYSJziENnZSRLkjYf4DIPACC2EVDCiO++PNw4EAAQ6wgoYYQN2wAAaEdACSMXdmzYtqWsWs2tXourAQDAOgSUMHLOiCFKT0lQY4tX27hxIAAghhFQwohhGP5RlA2lLDcGAMQuAkqYuSg/Q5K0obTK4koAALAOASXMTM9vX8nzyb5qtXm5cSAAIDYRUMLMhOw0pTriVNvUqs8rPFaXAwCAJQgoYcZuMzSNeSgAgBhHQAlDJ+ehEFAAALGJgBKGLuqYh7Jh3zGZJvNQAACxh4AShiaNdCox3qZjJ5r11ZE6q8sBAGDQEVDCUEKcTVNHtc9D+ZjLPACAGERACVP+yzwEFABADCKghClfQPl4L/NQAACxh4ASpqbkDVO83ZDb06iyYw1WlwMAwKAioISppAS7zs8dKkn6mG3vAQAxhoASxpiHAgCIVQSUMNZ5PxQAAGIJASWMFY4eJpsh7a+ql7um0epyAAAYNASUMJaWGK/zctIkMQ8FABBbCChh7pIx7ffl+WgvAQUAEDsIKGFuxtmZkqT1XxFQAACxg4AS5i7MT5fdZmh/Vb3Kq+utLgcAgEFBQAlzQxxxmpzrlCT9g1EUAECMIKBEAN9lHgIKACBWEFAiwIyz2yfKrv+qivvyAABiAgElAkwdPUwJcTa5PY0qPXrC6nIAAAg5AkoESIy3q3DUMEms5gEAxAYCSoTwXeZhHgoAIBb0OaB8+OGHuuaaa5STkyPDMPTmm28GHDdNU0uXLlVOTo6SkpI0e/Zs7dixI6BNU1OTFi1apMzMTKWkpOjaa69VeXn5gD5ItJtxTkdA2Vslr5d5KACA6NbngHLixAlNnjxZTz75ZLfHH330UT322GN68skntXHjRrlcLl155ZWqra31tykqKtKqVau0cuVKrVu3TnV1dbr66qvV1tbW/08S5c7PHarkBLuOnWjWrsO1Zz4BAIAIFtfXE+bPn6/58+d3e8w0TT3xxBN6+OGHdf3110uSnn/+eWVlZemVV17R97//fdXU1OjZZ5/Viy++qLlz50qSXnrpJeXl5em9997TVVddNYCPE73i7TZdlJ+uD3Yd0fqvqjQhO83qkgAACJmgzkEpLS2V2+3WvHnz/M85HA7NmjVL69evlyRt2rRJLS0tAW1ycnJUUFDgb9NVU1OTPB5PwCMWnZyHctTiSgAACK2gBhS32y1JysrKCng+KyvLf8ztdishIUHDhg3rsU1Xy5cvl9Pp9D/y8vKCWXbE8G3Y9vHeY2pt81pcDQAAoROSVTyGYQR8bZrmKc91dbo2S5YsUU1Njf9RVlYWtFojyYTsNDmT4lXb1Krth2JzFAkAEBuCGlBcLpcknTISUllZ6R9Vcblcam5uVnV1dY9tunI4HEpLSwt4xCK7zdDFY9IlSeu5zAMAiGJBDSj5+flyuVwqLi72P9fc3KySkhLNmDFDklRYWKj4+PiANhUVFdq+fbu/DXrGfXkAALGgz6t46urq9OWXX/q/Li0t1datW5Wenq5Ro0apqKhIy5Yt09ixYzV27FgtW7ZMycnJuvXWWyVJTqdTd955p+6//35lZGQoPT1dDzzwgCZNmuRf1YOe+SbKbig9psaWNiXG2y2uCACA4OtzQPnkk080Z84c/9eLFy+WJC1cuFArVqzQgw8+qIaGBt19992qrq7W9OnT9e677yo1NdV/zuOPP664uDjdeOONamho0BVXXKEVK1bIbueX7ZmcM2KIXGmJcnsatXHfMV06drjVJQEAEHSGGYG3x/V4PHI6naqpqYnJ+Sg/eu1TvbapXP9y2Rj95BsTrC4HAIBe6cvvb+7FE4EuHdc+avLh7iMWVwIAQGgQUCLQzHMyZRjSF+5aVXoarS4HAICgI6BEoPSUBE0a6ZQkfbiH5cYAgOhDQIlQl3VMjl27h8s8AIDoQ0CJUJeObd8PZe2eo/J6I26eMwAAp0VAiVBTRw9TSoJdx040a2cF294DAKILASVCxdttuqRjV9kSVvMAAKIMASWCzRrnu8xDQAEARBcCSgTz7SK7aX+1TjS1WlwNAADBQ0CJYGdlpmhUerJa2kx9tJebBwIAogcBJcL5VvOwqywAIJoQUCLcZeN8+6GwYRsAIHoQUCLcJWdnyG4ztPfoCZUdq7e6HAAAgoKAEuHSEuM1ddRQSdKHrOYBAEQJAkoUmNVxmWfNFwQUAEB0IKBEgTnjR0iS/v7lUTW2tFlcDQAAA0dAiQLnZafJlZaohpY2lhsDAKICASUKGIbhH0V5/4tKi6sBAGDgCChR4oqOgPK3zytlmtzdGAAQ2QgoUeJr52TKEWfTweMN2lNZZ3U5AAAMCAElSiQl2HXJ2RmS2kdRAACIZASUKHKFfx7KYYsrAQBgYAgoUcQ3UXbT/modr2+2uBoAAPqPgBJFcocl69ysVHlNqYSbBwIAIhgBJcpcPuHkah4AACIVASXK+OahlOw+otY2r8XVAADQPwSUKDNl1DANTY5XTUOLNh84bnU5AAD0CwElyththmZ33Dzwb6zmAQBEKAJKFPKt5lnDtvcAgAhFQIlCs8eNkN1maPfhOu2vOmF1OQAA9BkBJQo5k+N18Zh0SdI7O9wWVwMAQN8RUKLUVRNdkqS/biegAAAiDwElSs07rz2gbD5wXJWeRourAQCgbwgoUcrlTNSUUUMlSe/sZDUPACCyEFCimO8yzztc5gEARBgCShTzBZSP9lZx80AAQEQhoESx/MwUjXelqtVrcm8eAEBEIaBEuXm+yzwsNwYARBACSpT7ekdAKdl9RPXNrRZXAwBA7xBQotyE7FTlpSepqdWrkl1HrC4HAIBeIaBEOcMw/KMoXOYBAEQKAkoM+HpBe0D52xeVam71WlwNAABnRkCJAVPyhml4qkO1ja36x94qq8sBAOCMCCgxwGYzNO+8LEnSX7ZVWFwNAABnRkCJEQsmZUuS/rLdzWUeAEDYI6DEiOljMjQi1aGahhat3cNqHgBAeCOgxAi7zdCC89tHUf706SGLqwEA4PQIKDHkmsk5kqR3dx5WQ3ObxdUAANAzAkoMmZI3VHnpSapvbtPfvjhsdTkAAPSIgBJDDMPQNee3j6JwmQcAEM4IKDHGd5lnza4j8jS2WFwNAADdI6DEmPGuVI0dMUTNrV69s52t7wEA4YmAEmMMw9C1HaMof/qMTdsAAOGJgBKDfJd5/v7lUVXVNVlcDQAApyKgxKCzMlN0fq5TbV5Tq9n6HgAQhggoMcp/medTAgoAIPwQUGLUgvOzZRjShn3HVF5db3U5AAAEIKDEqGxnki7Oz5AkvbH5oMXVAAAQiIASw741LVeS9F+byuX1mhZXAwDASQSUGDa/IFtDHHE6cKxeG/cds7ocAAD8CCgxLCnBrqs77nD82qZyi6sBAOAkAkqM813mWb2tQieaWi2uBgCAdgSUGDd11DCNyUxRfXOb3mZPFABAmAh6QFm6dKkMwwh4uFwu/3HTNLV06VLl5OQoKSlJs2fP1o4dO4JdBnrJMAzdUNgxWfYTLvMAAMJDSEZQJk6cqIqKCv9j27Zt/mOPPvqoHnvsMT355JPauHGjXC6XrrzyStXW1oaiFPTCDVNzZevYE2Xf0RNWlwMAQGgCSlxcnFwul/8xfPhwSe2jJ0888YQefvhhXX/99SooKNDzzz+v+vp6vfLKK6EoBb3gcibq0rHt36P/YrIsACAMhCSg7NmzRzk5OcrPz9fNN9+svXv3SpJKS0vldrs1b948f1uHw6FZs2Zp/fr1Pb5eU1OTPB5PwAPB5Zss+/rmcrWxJwoAwGJBDyjTp0/XCy+8oHfeeUfPPPOM3G63ZsyYoaqqKrndbklSVlZWwDlZWVn+Y91Zvny5nE6n/5GXlxfssmPe3AlZcibFq6KmUeu/Omp1OQCAGBf0gDJ//nzdcMMNmjRpkubOnau3335bkvT888/72xiGEXCOaZqnPNfZkiVLVFNT43+UlZUFu+yYlxhv1z9d0H4DwVc30r8AAGuFfJlxSkqKJk2apD179vhX83QdLamsrDxlVKUzh8OhtLS0gAeC76YL20em3tnhVmVto8XVAABiWcgDSlNTkz7//HNlZ2crPz9fLpdLxcXF/uPNzc0qKSnRjBkzQl0KzmBijlOFo4eppc3Uyg2MogAArBP0gPLAAw+opKREpaWl+vjjj/XP//zP8ng8WrhwoQzDUFFRkZYtW6ZVq1Zp+/btuuOOO5ScnKxbb7012KWgH26/eLQk6ZWPD6i1zWtxNQCAWBUX7BcsLy/XLbfcoqNHj2r48OG6+OKL9dFHH2n06PZffA8++KAaGhp09913q7q6WtOnT9e7776r1NTUYJeCfpg/yaX//ecEuT2NKt55WPMnZVtdEgAgBhmmaUbcmlKPxyOn06mamhrmo4TA/3nnC/1mzVe6ZEyG/vAvF1tdDgAgSvTl9zf34sEpbp0+WjZD+sfeKu05zA6/AIDBR0DBKUYOTdLcCe2rql78aL/F1QAAYhEBBd36ziVnSZLe2HxQdU2t1hYDAIg5BBR062vnZGjM8BTVNbVq1ZaDVpcDAIgxBBR0yzAM3Ta9feXVi//YpwicSw0AiGAEFPTohsJcJcXbtftwndZ/VWV1OQCAGEJAQY+cSfH+uxz/ruQri6sBAMQSAgpO63uXjpHdZmjtnqPafrDG6nIAADGCgILTyktP1oKO3WT//cO9FlcDAIgVBBSc0fdnjZEkvf3ZIe2vOmFxNQCAWEBAwRlNzHHqsnHD5TWlZ9YyigIACD0CCnrlB7POliS99km5jtY1WVwNACDaEVDQKxePSdfkvKFqavVqxd/3WV0OACDKEVDQK4Zh6Acdc1Fe+Mc+tr8HAIQUAQW9duV5Lo3JTJGnsVV/+PiA1eUAAKIYAQW9ZrcZ/hU9T6/dq/pmRlEAAKFBQEGffHNKrvLSk3Sktkkr1u+zuhwAQJQioKBPEuJs+uHccZKk333wlWrqWyyuCAAQjQgo6LN/umCkxmUNkaexVU+v5R49AIDgI6Cgz+w2Qw/MO1eS9Pt1+1RZ22hxRQCAaENAQb9ceV6WLsgbqoaWNv3m/S+tLgcAEGUIKOgXwzD04FXtoyivbDigsmP1FlcEAIgmBBT024xzMjXznEy1tJl6/L3dVpcDAIgiBBQMyI86RlFWbTmoXe5ai6sBAEQLAgoGZHLeUM0vcMk0pZ+9tV2maVpdEgAgChBQMGA/+cYEJcbb9NHeY3rr00NWlwMAiAIEFAxYXnqy7p1zjiTpF29/Lk8jm7cBAAaGgIKg+N5lY5SfmaIjtU16vJgJswCAgSGgICgccXb9r2snSpKeX79POw95LK4IABDJCCgImsvGDdc3JrnkNaX/+cft8nqZMAsA6B8CCoLqf1x9npIT7Ppkf7Ve31xudTkAgAhFQEFQZTuTdN8VYyVJv1z9uQ57uE8PAKDvCCgIuu/OzNfEnDQdr2/RA699yqUeAECfEVAQdPF2m/7fzVOUGG/T2j1H9fu/l1pdEgAgwhBQEBLnjBii/3H1eZKkR/+6i1U9AIA+IaAgZG69aJTmTshSc5tX963cosaWNqtLAgBECAIKQsYwDP3qhkkanurQnso6LV/9udUlAQAiBAEFIZUxxKH/+63JkqTn/7Ff7+xwW1wRACASEFAQcrPGDdedM/MlSUUrt2pbeY3FFQEAwh0BBYPix/PH69KxmWpoadN3n9+og8cbrC4JABDGCCgYFPF2m3777aka70rVkdomffe5jarlrscAgB4QUDBoUhPj9ewdF2p4qkO7Dtfq7pc3q6XNa3VZAIAwREDBoBo5NEm/X3ihkuLtWrvnqH66ipsKAgBORUDBoJuU69Svb5kiw5Be/aRM97/2KSMpAIAABBRY4srzsvT4jRcozmZo1ZaD+t4Ln6i+udXqsgAAYYKAAstcN2Wknlk4TYnxNn2w64hu+4+Pdby+2eqyAABhgIACS805d4Re/u/TlZYYp80HjuvGf/+HyqvrrS4LAGAxAgosVzg6Xa/dNUNZaQ7tPlyn+U+s1X9uLJNpMnkWAGIVAQVh4VxXql7/wQxNHTVUtU2tevD1z/TdFRt12NNodWkAAAsQUBA2cocl67W7ZmjJ/PFKsNu0ZtcRXflYif7zkzJW+QBAjDHMCBxH93g8cjqdqqmpUVpamtXlIAT2HK7V/a99qs867tuT7UzU7ZeM1i0XjtKwlASLqwMA9Edffn8TUBC2Wtu8+o91pfqPtXt1tK59dU9ivE3fnJKr66eO1JS8oYqzMwgIAJGCgIKo0tTapj99WqHfryvVzgqP/3lnUrxmjRuuy8eP0KVjM5UxxGFhlQCAMyGgICqZpqkNpcf0yoYD+mDXEdU0BN5scESqQ+e6UjUuK1XnZqVqeJpDaYlxGuKI15DEOKUk2GXIaG/s+8eQbIYhW8e/vucMGR3/SkbHcaPjOACgfwgoiHqtbV5tKTuuNV9U6v0vKvWFu3ZQ3rdzaDHUJcx0/LcvzBiS1E3I8Z/vP3ZqIPK9nq3b9t2998nnbF3bdvz3yeeNTnUFPu/LYKe8Rg8122yBr9fdeQr4HIH9JX9/BfadurQ9tU8Dz/O9p7r2g+91unzGzm3U+fvT5XP6Xq/z57IZnfuv83v01Idd+q1zf3auo4fvr83o+pkDX09df3Y6vXdAHafUd/Lc7r4/6lJv5z6QEfi5Aj6rreefU3X5XIH9Z/T2f4aIYAQUxJy6plbtOVyr3Ydrtctdpz2VtTp2olm1ja2qa2pVbWOLWtoi7kcdiDndha3Ogfp0fwT0JlQHBtMe/kDoeN2eg1tgMLX5z+ncvvuQ1tN/d33dzu8dGEK7nN9N4O36OboN9Kd5XV//DE916J455wT1+9uX399xQX1nwCJDHHGaMmqYpowa1mObrkuVTVMyZco0Ja9pytvxr2lK6nTMVPvlJdN3Tuf/7nS+L+r7v+44r/1mze3/nu6czu/nO3am9+36Xh1v1fNx/+fp5vP1cJ4Cag48T6bvc52szdvxocwezpMkr7ebz9JNHb7z1Ol4137stl86vlaXvu7czveavmPdfd6utZz8PnZ+T/k3FTz5fevaT12+753OVcfXged28z3paNO5L7r7eQioo0vt3f08n/E1O9Xi7yOdfK9g69wvHc+E5o1wRmOGpwQ9oPQFAQUxI54VP0DQdQ0vpwve/sDeXQDq2r5rqDvNa/rPPcPr+M7vGuo7h9nOr9U1IHcOup0/e/d/EPh76JQ/PLwnD572D46Tx08TynsIy6eG4c590PMfK50D87Bka7d0IKAAAPrNdxnFJuaQILj4kxIAAIQdAgoAAAg7BBQAABB2CCgAACDsEFAAAEDYsTSg/Pa3v1V+fr4SExNVWFiotWvXWlkOAAAIE5YFlFdffVVFRUV6+OGHtWXLFl166aWaP3++Dhw4YFVJAAAgTFi21f306dM1depUPfXUU/7nJkyYoOuuu07Lly8/7blsdQ8AQOTpy+9vS0ZQmpubtWnTJs2bNy/g+Xnz5mn9+vWntG9qapLH4wl4AACA6GVJQDl69Kja2tqUlZUV8HxWVpbcbvcp7ZcvXy6n0+l/5OXlDVapAADAApZOku16e23TNLu95faSJUtUU1Pjf5SVlQ1WiQAAwAKW3IsnMzNTdrv9lNGSysrKU0ZVJMnhcMjhcAxWeQAAwGKWjKAkJCSosLBQxcXFAc8XFxdrxowZVpQEAADCiGV3M168eLFuv/12TZs2TZdccomefvppHThwQHfdddcZz/UtPGKyLAAAkcP3e7s3C4gtCyg33XSTqqqq9POf/1wVFRUqKCjQ6tWrNXr06DOeW1tbK0lMlgUAIALV1tbK6XSeto1l+6AMhNfr1aFDh5SamtrtpNqB8Hg8ysvLU1lZGXushBh9PXjo68FDXw8e+nrwBKuvTdNUbW2tcnJyZLOdfpaJZSMoA2Gz2ZSbmxvS90hLS+MHfpDQ14OHvh489PXgoa8HTzD6+kwjJz7cLBAAAIQdAgoAAAg7BJQuHA6Hfvazn7HvyiCgrwcPfT146OvBQ18PHiv6OiInyQIAgOjGCAoAAAg7BBQAABB2CCgAACDsEFAAAEDYIaB08tvf/lb5+flKTExUYWGh1q5da3VJEW/58uW68MILlZqaqhEjRui6667Trl27AtqYpqmlS5cqJydHSUlJmj17tnbs2GFRxdFj+fLlMgxDRUVF/ufo6+A5ePCgbrvtNmVkZCg5OVkXXHCBNm3a5D9OXwdHa2urfvrTnyo/P19JSUkaM2aMfv7zn8vr9frb0Nf99+GHH+qaa65RTk6ODMPQm2++GXC8N33b1NSkRYsWKTMzUykpKbr22mtVXl4+8OJMmKZpmitXrjTj4+PNZ555xty5c6d53333mSkpKeb+/futLi2iXXXVVeZzzz1nbt++3dy6dau5YMECc9SoUWZdXZ2/zSOPPGKmpqaar7/+urlt2zbzpptuMrOzs02Px2Nh5ZFtw4YN5llnnWWef/755n333ed/nr4OjmPHjpmjR48277jjDvPjjz82S0tLzffee8/88ssv/W3o6+D4xS9+YWZkZJh//vOfzdLSUvO1114zhwwZYj7xxBP+NvR1/61evdp8+OGHzddff92UZK5atSrgeG/69q677jJHjhxpFhcXm5s3bzbnzJljTp482WxtbR1QbQSUDhdddJF51113BTw3fvx488c//rFFFUWnyspKU5JZUlJimqZper1e0+VymY888oi/TWNjo+l0Os3f/e53VpUZ0Wpra82xY8eaxcXF5qxZs/wBhb4OnoceesicOXNmj8fp6+BZsGCB+d3vfjfgueuvv9687bbbTNOkr4Opa0DpTd8eP37cjI+PN1euXOlvc/DgQdNms5l//etfB1QPl3gkNTc3a9OmTZo3b17A8/PmzdP69estqio61dTUSJLS09MlSaWlpXK73QF973A4NGvWLPq+n+655x4tWLBAc+fODXievg6et956S9OmTdO3vvUtjRgxQlOmTNEzzzzjP05fB8/MmTP1t7/9Tbt375Ykffrpp1q3bp2+8Y1vSKKvQ6k3fbtp0ya1tLQEtMnJyVFBQcGA+z8ibxYYbEePHlVbW5uysrICns/KypLb7baoquhjmqYWL16smTNnqqCgQJL8/dtd3+/fv3/Qa4x0K1eu1ObNm7Vx48ZTjtHXwbN371499dRTWrx4sX7yk59ow4YN+td//Vc5HA595zvfoa+D6KGHHlJNTY3Gjx8vu92utrY2/fKXv9Qtt9wiiZ/rUOpN37rdbiUkJGjYsGGntBno708CSieGYQR8bZrmKc+h/+6991599tlnWrdu3SnH6PuBKysr03333ad3331XiYmJPbajrwfO6/Vq2rRpWrZsmSRpypQp2rFjh5566il95zvf8bejrwfu1Vdf1UsvvaRXXnlFEydO1NatW1VUVKScnBwtXLjQ346+Dp3+9G0w+p9LPJIyMzNlt9tPSXuVlZWnJEf0z6JFi/TWW29pzZo1ys3N9T/vcrkkib4Pgk2bNqmyslKFhYWKi4tTXFycSkpK9Otf/1pxcXH+/qSvBy47O1vnnXdewHMTJkzQgQMHJPFzHUw/+tGP9OMf/1g333yzJk2apNtvv10//OEPtXz5ckn0dSj1pm9dLpeam5tVXV3dY5v+IqBISkhIUGFhoYqLiwOeLy4u1owZMyyqKjqYpql7771Xb7zxht5//33l5+cHHM/Pz5fL5Qro++bmZpWUlND3fXTFFVdo27Zt2rp1q/8xbdo0ffvb39bWrVs1ZswY+jpIvva1r52yXH737t0aPXq0JH6ug6m+vl42W+CvKrvd7l9mTF+HTm/6trCwUPHx8QFtKioqtH379oH3/4Cm2EYR3zLjZ5991ty5c6dZVFRkpqSkmPv27bO6tIj2gx/8wHQ6neYHH3xgVlRU+B/19fX+No888ojpdDrNN954w9y2bZt5yy23sEQwSDqv4jFN+jpYNmzYYMbFxZm//OUvzT179pgvv/yymZycbL700kv+NvR1cCxcuNAcOXKkf5nxG2+8YWZmZpoPPvigvw193X+1tbXmli1bzC1btpiSzMcee8zcsmWLf4uN3vTtXXfdZebm5prvvfeeuXnzZvPyyy9nmXGw/eY3vzFHjx5tJiQkmFOnTvUvhUX/Ser28dxzz/nbeL1e82c/+5npcrlMh8NhXnbZZea2bdusKzqKdA0o9HXw/OlPfzILCgpMh8Nhjh8/3nz66acDjtPXweHxeMz77rvPHDVqlJmYmGiOGTPGfPjhh82mpiZ/G/q6/9asWdPt/0cvXLjQNM3e9W1DQ4N57733munp6WZSUpJ59dVXmwcOHBhwbYZpmubAxmAAAACCizkoAAAg7BBQAABA2CGgAACAsENAAQAAYYeAAgAAwg4BBQAAhB0CCgAACDsEFAAAEHYIKAAAIOwQUAAAQNghoAAAgLBDQAEAAGHn/wPe7Ye31J//uQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "epochs = [i for i in range(100)]\n",
    "plt.plot(epochs, losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(19.9823, grad_fn=<DivBackward0>)\n",
      "[-1.59017107 -2.01624809 -0.79297536 -0.97102047  0.          0.        ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mara/anaconda3/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([256, 6])) that is different to the input size (torch.Size([6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/mara/anaconda3/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([256, 6])) that is different to the input size (torch.Size([6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/mara/anaconda3/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([256, 6])) that is different to the input size (torch.Size([6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/mara/anaconda3/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([256, 6])) that is different to the input size (torch.Size([6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/mara/anaconda3/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([256, 6])) that is different to the input size (torch.Size([6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/mara/anaconda3/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64, 6])) that is different to the input size (torch.Size([6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    }
   ],
   "source": [
    "gnn.model.eval()\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "mse = 0\n",
    "total = 0 \n",
    "r2_scores = []\n",
    "for graph in train_loader:\n",
    "    output = gnn.model(graph.x, graph.edge_index, graph.batch)\n",
    "    output = torch.sum(output, dim=1)\n",
    "    y_true = graph.y.reshape(int(len(graph.y)/6), 6)\n",
    "    padded_output = torch.nn.functional.pad(output, (0, 256 - int(len(graph.y)/6)))\n",
    "    y_pred = probe(padded_output)\n",
    "    \n",
    "    mse += loss_fn(y_pred, y_true)\n",
    "    total += 1\n",
    "\n",
    "    # Calculate R2 score per property\n",
    "    r2_per_property = []\n",
    "    y_true = y_true.T\n",
    "    for i in range(len(y_true)):\n",
    "        predictions = y_pred[i].detach().numpy().repeat(len(y_true[i]))\n",
    "        r2 = r2_score(y_true[i], predictions)\n",
    "        r2_per_property.append(r2)\n",
    "    r2_scores.append(r2_per_property)\n",
    "\n",
    "r2_scores = np.mean(r2_scores, axis=0)\n",
    "print(mse/total)\n",
    "print(r2_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mara/anaconda3/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([256, 6])) that is different to the input size (torch.Size([6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/mara/anaconda3/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([256, 6])) that is different to the input size (torch.Size([6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/mara/anaconda3/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([256, 6])) that is different to the input size (torch.Size([6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/mara/anaconda3/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([256, 6])) that is different to the input size (torch.Size([6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/mara/anaconda3/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([256, 6])) that is different to the input size (torch.Size([6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/mara/anaconda3/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([256, 6])) that is different to the input size (torch.Size([6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/mara/anaconda3/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64, 6])) that is different to the input size (torch.Size([6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(19.9823, grad_fn=<DivBackward0>)\n",
      "0.7556661984785487\n",
      "[0.8324555307414964, 0.7941675084346029, 0.8303284134234526, 0.8234154997963283, 0.7925062498514386, 0.7960124544203672, 0.4207777326821539]\n"
     ]
    }
   ],
   "source": [
    "gnn.model.eval()\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "mse = 0\n",
    "total = 0 \n",
    "r2_scores = []\n",
    "for graph in train_loader:\n",
    "    output = gnn.model(graph.x, graph.edge_index, graph.batch)\n",
    "    output = torch.sum(output, dim=1)\n",
    "    y_true = graph.y.reshape(int(len(graph.y)/6), 6)\n",
    "    padded_output = torch.nn.functional.pad(output, (0, 256 - int(len(graph.y)/6)))\n",
    "    y_pred = probe(padded_output)\n",
    "    \n",
    "    mse += loss_fn(y_pred, y_true)\n",
    "    total += 1\n",
    "\n",
    "    # Calculate R2 score per property\n",
    "    r2_per_property = []\n",
    "    for i in range(len(y_true)):\n",
    "        r2 = r2_score(y_true[i], y_pred.detach().numpy())\n",
    "        r2_per_property.append(r2)\n",
    "    \n",
    "    r2_per_property = np.mean(r2_per_property)\n",
    "    r2_scores.append(r2_per_property)\n",
    "\n",
    "# r2_scores = np.mean(r2_scores, axis=0)\n",
    "print(mse/total)\n",
    "print(np.mean(r2_scores))\n",
    "print(r2_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
