{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data, Dataset\n",
    "import networkx as nx\n",
    "from networkx.algorithms.centrality import betweenness_centrality\n",
    "\n",
    "from Datasets.synthetics import BA_2grid, BA_2grid_house, ProbingDataset, BA_2grid_to_test\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "import torch_geometric.utils as pyg_utils\n",
    "import networkx as nx\n",
    "from networkx.algorithms.centrality import betweenness_centrality\n",
    "\n",
    "import pickle as pkl\n",
    "from torch_geometric.utils import from_networkx\n",
    "import random\n",
    "\n",
    "from models.models_BA_2grid import Cheb_framework as framework\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    if seed == -1:\n",
    "        seed = random.randint(0, 1000)\n",
    "    # Pandas also uses np random state by default\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    # if you are using GPU\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.enabled = False\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(43)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute Graph-Features Dataset\n",
    "\n",
    "The features for BA-2grid-house and ER-nb_stars2 datasets:\n",
    "- num_nodes\n",
    "- num_edges\n",
    "- density\n",
    "- average_shortest_path_length\n",
    "- transitivity\n",
    "- average_clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "probing_dataset = ProbingDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ProbingDataset(2000)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probing_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnn_dataset_to_test = BA_2grid_to_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = torch.arange(len(gnn_dataset_to_test))\n",
    "train_idx, test_idx = train_test_split(idx, train_size=0.8,random_state=10)\n",
    "\n",
    "train_loader = DataLoader(gnn_dataset_to_test[train_idx],batch_size=256)\n",
    "test_loader = DataLoader(gnn_dataset_to_test[test_idx],batch_size=256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have a list of graphs in your dataset\n",
    "idx = torch.arange(len(probing_dataset))\n",
    "train_idx, test_idx = train_test_split(idx, train_size=0.8,random_state=10)\n",
    "\n",
    "probe_train_loader = DataLoader(probing_dataset[train_idx],batch_size=256)\n",
    "probe_test_loader = DataLoader(probing_dataset[test_idx],batch_size=256)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model to Probe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mara/anaconda3/lib/python3.9/site-packages/torch_geometric/data/in_memory_dataset.py:157: UserWarning: It is not recommended to directly access the internal storage format `data` of an 'InMemoryDataset'. If you are absolutely certain what you are doing, access the internal storage via `InMemoryDataset._data` instead to suppress this warning. Alternatively, you can access stacked individual attributes of every graph via `dataset.{attr_name}`.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "MODEL = \"Chab\"\n",
    "DATASET = \"BA_2grid\"\n",
    "dataset = BA_2grid()\n",
    "gnn = framework(dataset,device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6990147439708688"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model\n",
    "gnn.train()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train probe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Probe(torch.nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(Probe, self).__init__()\n",
    "        self.fc = torch.nn.Linear(input_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.fc(x.float())\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_probe(probe, gnn, layer_idx):\n",
    "    gnn.model.eval()\n",
    "    probe.train()\n",
    "    \n",
    "    total_loss = 0\n",
    "    loss_fn = torch.nn.MSELoss()\n",
    "    optimizer = optim.Adam(probe.parameters(), lr=0.001)\n",
    "\n",
    "    for graph in probe_train_loader:\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = gnn.model(graph.x, graph.edge_index, graph.batch)\n",
    "        output = torch.sum(output, dim=1)\n",
    "        labels = graph.y.reshape(int(len(graph.y)/6), 6)\n",
    "        padded_output = torch.nn.functional.pad(output, (0, 256 - int(len(graph.y)/6)))\n",
    "        output = probe(padded_output)\n",
    "        \n",
    "        \n",
    "        loss = loss_fn(output, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += float(loss) * graph.num_graphs\n",
    "    return total_loss / len(probe_train_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "def evaluate_probe(probe, test_loader):\n",
    "    probe.eval()\n",
    "\n",
    "    mse = 0\n",
    "    r2 = 0\n",
    "    total = 0\n",
    "    loss_fn = torch.nn.MSELoss()\n",
    "    \n",
    "    for graph in test_loader:\n",
    "\n",
    "        output = gnn.model(graph.x, graph.edge_index, graph.batch)\n",
    "        output = torch.sum(output, dim=1)\n",
    "        y_true = graph.y.reshape(int(len(graph.y)/6), 6)\n",
    "        padded_output = torch.nn.functional.pad(output, (0, 256 - int(len(graph.y)/6)))\n",
    "        y_pred = probe(padded_output)\n",
    "\n",
    "        mse += loss_fn(y_pred, y_true)\n",
    "        # r2 += r2_score(y_true, y_pred)\n",
    "        total += 1\n",
    "    \n",
    "    return {\n",
    "        \"MSE\": mse/total\n",
    "        # \"R2 Score\": r2/total\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_to_train(gnn, layer_idx, num_epochs=10):\n",
    "    probe = Probe(256, 6)\n",
    "    losses = []\n",
    "    test_losses = []\n",
    "    for epoch in range(num_epochs):\n",
    "        loss = train_probe(probe, gnn, layer_idx)\n",
    "        losses.append(loss)\n",
    "        result = evaluate_probe(probe, probe_test_loader)\n",
    "        test_acc = result['MSE']\n",
    "        test_losses.append(test_acc)\n",
    "        print(f'Epoch: {epoch:03d}, '\n",
    "              f'Test MSE: {test_acc:.3f}',\n",
    "              f'Train MSE: {loss:.3f}')\n",
    "        # print(f'Epoch: {epoch:03d}, '\n",
    "        #       f'Loss: {loss:.3f}, ')\n",
    "    return probe, losses, test_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mara/anaconda3/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([256, 6])) that is different to the input size (torch.Size([6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/mara/anaconda3/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64, 6])) that is different to the input size (torch.Size([6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/mara/anaconda3/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([144, 6])) that is different to the input size (torch.Size([6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Test MSE: 205.885 Train MSE: 217.691\n",
      "Epoch: 001, Test MSE: 177.732 Train MSE: 180.986\n",
      "Epoch: 002, Test MSE: 152.578 Train MSE: 149.053\n",
      "Epoch: 003, Test MSE: 129.616 Train MSE: 120.616\n",
      "Epoch: 004, Test MSE: 108.864 Train MSE: 95.407\n",
      "Epoch: 005, Test MSE: 90.317 Train MSE: 73.427\n",
      "Epoch: 006, Test MSE: 73.993 Train MSE: 54.673\n",
      "Epoch: 007, Test MSE: 59.893 Train MSE: 39.153\n",
      "Epoch: 008, Test MSE: 48.024 Train MSE: 26.853\n",
      "Epoch: 009, Test MSE: 38.399 Train MSE: 17.776\n",
      "Epoch: 010, Test MSE: 31.067 Train MSE: 11.895\n",
      "Epoch: 011, Test MSE: 27.215 Train MSE: 9.144\n",
      "Epoch: 012, Test MSE: 26.521 Train MSE: 8.484\n",
      "Epoch: 013, Test MSE: 26.949 Train MSE: 8.476\n",
      "Epoch: 014, Test MSE: 26.374 Train MSE: 8.429\n",
      "Epoch: 015, Test MSE: 26.684 Train MSE: 8.420\n",
      "Epoch: 016, Test MSE: 26.185 Train MSE: 8.376\n",
      "Epoch: 017, Test MSE: 26.415 Train MSE: 8.363\n",
      "Epoch: 018, Test MSE: 25.980 Train MSE: 8.325\n",
      "Epoch: 019, Test MSE: 26.149 Train MSE: 8.310\n",
      "Epoch: 020, Test MSE: 25.767 Train MSE: 8.272\n",
      "Epoch: 021, Test MSE: 25.888 Train MSE: 8.256\n",
      "Epoch: 022, Test MSE: 25.549 Train MSE: 8.219\n",
      "Epoch: 023, Test MSE: 25.631 Train MSE: 8.200\n",
      "Epoch: 024, Test MSE: 25.328 Train MSE: 8.166\n",
      "Epoch: 025, Test MSE: 25.377 Train MSE: 8.146\n",
      "Epoch: 026, Test MSE: 25.105 Train MSE: 8.114\n",
      "Epoch: 027, Test MSE: 25.128 Train MSE: 8.094\n",
      "Epoch: 028, Test MSE: 24.881 Train MSE: 8.060\n",
      "Epoch: 029, Test MSE: 24.882 Train MSE: 8.039\n",
      "Epoch: 030, Test MSE: 24.657 Train MSE: 8.009\n",
      "Epoch: 031, Test MSE: 24.639 Train MSE: 7.986\n",
      "Epoch: 032, Test MSE: 24.432 Train MSE: 7.958\n",
      "Epoch: 033, Test MSE: 24.400 Train MSE: 7.933\n",
      "Epoch: 034, Test MSE: 24.208 Train MSE: 7.905\n",
      "Epoch: 035, Test MSE: 24.162 Train MSE: 7.883\n",
      "Epoch: 036, Test MSE: 23.985 Train MSE: 7.853\n",
      "Epoch: 037, Test MSE: 23.928 Train MSE: 7.830\n",
      "Epoch: 038, Test MSE: 23.761 Train MSE: 7.804\n",
      "Epoch: 039, Test MSE: 23.697 Train MSE: 7.778\n",
      "Epoch: 040, Test MSE: 23.539 Train MSE: 7.753\n",
      "Epoch: 041, Test MSE: 23.467 Train MSE: 7.730\n",
      "Epoch: 042, Test MSE: 23.318 Train MSE: 7.701\n",
      "Epoch: 043, Test MSE: 23.240 Train MSE: 7.679\n",
      "Epoch: 044, Test MSE: 23.098 Train MSE: 7.651\n",
      "Epoch: 045, Test MSE: 23.016 Train MSE: 7.629\n",
      "Epoch: 046, Test MSE: 22.879 Train MSE: 7.604\n",
      "Epoch: 047, Test MSE: 22.793 Train MSE: 7.578\n",
      "Epoch: 048, Test MSE: 22.661 Train MSE: 7.554\n",
      "Epoch: 049, Test MSE: 22.572 Train MSE: 7.528\n",
      "Epoch: 050, Test MSE: 22.445 Train MSE: 7.505\n",
      "Epoch: 051, Test MSE: 22.353 Train MSE: 7.482\n",
      "Epoch: 052, Test MSE: 22.230 Train MSE: 7.455\n",
      "Epoch: 053, Test MSE: 22.136 Train MSE: 7.433\n",
      "Epoch: 054, Test MSE: 22.017 Train MSE: 7.407\n",
      "Epoch: 055, Test MSE: 21.921 Train MSE: 7.386\n",
      "Epoch: 056, Test MSE: 21.805 Train MSE: 7.360\n",
      "Epoch: 057, Test MSE: 21.708 Train MSE: 7.337\n",
      "Epoch: 058, Test MSE: 21.593 Train MSE: 7.314\n",
      "Epoch: 059, Test MSE: 21.497 Train MSE: 7.289\n",
      "Epoch: 060, Test MSE: 21.383 Train MSE: 7.267\n",
      "Epoch: 061, Test MSE: 21.287 Train MSE: 7.242\n",
      "Epoch: 062, Test MSE: 21.175 Train MSE: 7.221\n",
      "Epoch: 063, Test MSE: 21.078 Train MSE: 7.195\n",
      "Epoch: 064, Test MSE: 20.969 Train MSE: 7.174\n",
      "Epoch: 065, Test MSE: 20.871 Train MSE: 7.151\n",
      "Epoch: 066, Test MSE: 20.764 Train MSE: 7.126\n",
      "Epoch: 067, Test MSE: 20.665 Train MSE: 7.105\n",
      "Epoch: 068, Test MSE: 20.560 Train MSE: 7.081\n",
      "Epoch: 069, Test MSE: 20.462 Train MSE: 7.060\n",
      "Epoch: 070, Test MSE: 20.358 Train MSE: 7.035\n",
      "Epoch: 071, Test MSE: 20.260 Train MSE: 7.014\n",
      "Epoch: 072, Test MSE: 20.155 Train MSE: 6.992\n",
      "Epoch: 073, Test MSE: 20.059 Train MSE: 6.967\n",
      "Epoch: 074, Test MSE: 19.955 Train MSE: 6.948\n",
      "Epoch: 075, Test MSE: 19.859 Train MSE: 6.923\n",
      "Epoch: 076, Test MSE: 19.756 Train MSE: 6.904\n",
      "Epoch: 077, Test MSE: 19.660 Train MSE: 6.878\n",
      "Epoch: 078, Test MSE: 19.560 Train MSE: 6.859\n",
      "Epoch: 079, Test MSE: 19.463 Train MSE: 6.837\n",
      "Epoch: 080, Test MSE: 19.363 Train MSE: 6.813\n",
      "Epoch: 081, Test MSE: 19.266 Train MSE: 6.793\n",
      "Epoch: 082, Test MSE: 19.168 Train MSE: 6.770\n",
      "Epoch: 083, Test MSE: 19.072 Train MSE: 6.749\n",
      "Epoch: 084, Test MSE: 18.973 Train MSE: 6.729\n",
      "Epoch: 085, Test MSE: 18.879 Train MSE: 6.704\n",
      "Epoch: 086, Test MSE: 18.780 Train MSE: 6.685\n",
      "Epoch: 087, Test MSE: 18.686 Train MSE: 6.661\n",
      "Epoch: 088, Test MSE: 18.590 Train MSE: 6.643\n",
      "Epoch: 089, Test MSE: 18.495 Train MSE: 6.621\n",
      "Epoch: 090, Test MSE: 18.399 Train MSE: 6.598\n",
      "Epoch: 091, Test MSE: 18.304 Train MSE: 6.578\n",
      "Epoch: 092, Test MSE: 18.210 Train MSE: 6.556\n",
      "Epoch: 093, Test MSE: 18.116 Train MSE: 6.536\n",
      "Epoch: 094, Test MSE: 18.021 Train MSE: 6.516\n",
      "Epoch: 095, Test MSE: 17.929 Train MSE: 6.492\n",
      "Epoch: 096, Test MSE: 17.835 Train MSE: 6.474\n",
      "Epoch: 097, Test MSE: 17.742 Train MSE: 6.453\n",
      "Epoch: 098, Test MSE: 17.649 Train MSE: 6.430\n",
      "Epoch: 099, Test MSE: 17.558 Train MSE: 6.411\n"
     ]
    }
   ],
   "source": [
    "probe, losses, test_acc = iterate_to_train(gnn, 0, num_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f3576338bb0>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "epochs = [i for i in range(100)]\n",
    "plt.plot(epochs, losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(15.5753, grad_fn=<DivBackward0>)\n",
      "[-1.01868578 -1.36602953 -0.70696467 -0.30496331  0.          0.        ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mara/anaconda3/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([256, 6])) that is different to the input size (torch.Size([6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/mara/anaconda3/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([256, 6])) that is different to the input size (torch.Size([6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/mara/anaconda3/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([256, 6])) that is different to the input size (torch.Size([6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/mara/anaconda3/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([256, 6])) that is different to the input size (torch.Size([6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/mara/anaconda3/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([256, 6])) that is different to the input size (torch.Size([6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/mara/anaconda3/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([256, 6])) that is different to the input size (torch.Size([6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/mara/anaconda3/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64, 6])) that is different to the input size (torch.Size([6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    }
   ],
   "source": [
    "gnn.model.eval()\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "mse = 0\n",
    "total = 0 \n",
    "r2_scores = []\n",
    "for graph in train_loader:\n",
    "    output = gnn.model(graph.x, graph.edge_index, graph.batch)\n",
    "    output = torch.sum(output, dim=1)\n",
    "    y_true = graph.y.reshape(int(len(graph.y)/6), 6)\n",
    "    padded_output = torch.nn.functional.pad(output, (0, 256 - int(len(graph.y)/6)))\n",
    "    y_pred = probe(padded_output)\n",
    "    \n",
    "    mse += loss_fn(y_pred, y_true)\n",
    "    total += 1\n",
    "\n",
    "    # Calculate R2 score per property\n",
    "    r2_per_property = []\n",
    "    for i in range(len(y_true)):\n",
    "        r2 = r2_score(y_true[i], y_pred.detach().numpy())\n",
    "        r2_per_property.append(r2)\n",
    "    \n",
    "    r2_scores.append(r2_per_property)\n",
    "\n",
    "print(mse/total)\n",
    "print(r2_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mara/anaconda3/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([256, 6])) that is different to the input size (torch.Size([6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/mara/anaconda3/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([256, 6])) that is different to the input size (torch.Size([6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/mara/anaconda3/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([256, 6])) that is different to the input size (torch.Size([6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/mara/anaconda3/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([256, 6])) that is different to the input size (torch.Size([6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/mara/anaconda3/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([256, 6])) that is different to the input size (torch.Size([6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n",
      "/home/mara/anaconda3/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([256, 6])) that is different to the input size (torch.Size([6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(15.5753, grad_fn=<DivBackward0>)\n",
      "0.8094981961696622\n",
      "[0.8581070980574541, 0.8282953847759253, 0.8623733676254801, 0.8527135186754542, 0.8281379948579171, 0.8308978910895, 0.6059621181059043]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mara/anaconda3/lib/python3.9/site-packages/torch/nn/modules/loss.py:536: UserWarning: Using a target size (torch.Size([64, 6])) that is different to the input size (torch.Size([6])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    }
   ],
   "source": [
    "gnn.model.eval()\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "mse = 0\n",
    "total = 0 \n",
    "r2_scores = []\n",
    "for graph in train_loader:\n",
    "    output = gnn.model(graph.x, graph.edge_index, graph.batch)\n",
    "    output = torch.sum(output, dim=1)\n",
    "    y_true = graph.y.reshape(int(len(graph.y)/6), 6)\n",
    "    padded_output = torch.nn.functional.pad(output, (0, 256 - int(len(graph.y)/6)))\n",
    "    y_pred = probe(padded_output)\n",
    "    \n",
    "    mse += loss_fn(y_pred, y_true)\n",
    "    total += 1\n",
    "\n",
    "    # Calculate R2 score per property\n",
    "    r2_per_property = []\n",
    "    for i in range(len(y_true)):\n",
    "        r2 = r2_score(y_true[i], y_pred.detach().numpy())\n",
    "        r2_per_property.append(r2)\n",
    "    \n",
    "    r2_per_property = np.mean(r2_per_property)\n",
    "    r2_scores.append(r2_per_property)\n",
    "\n",
    "# r2_scores = np.mean(r2_scores, axis=0)\n",
    "print(mse/total)\n",
    "print(np.mean(r2_scores))\n",
    "print(r2_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
